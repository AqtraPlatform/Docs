#!/usr/bin/env python3
"""
MkDocs Anchors Doctor - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —è–∫–æ—Ä–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
Enhanced version with proper slugify and safe fixes
"""

import os
import re
import csv
import sys
from pathlib import Path
from typing import List, Dict, Set, Optional, Tuple
import argparse

try:
    from pymdownx.slugs import slugify
except ImportError:
    # Fallback slugify function
    def slugify(text, max_length=0, word_boundary=False, separator="-", stopwords=None):
        """Simple slugify function"""
        import unicodedata
        import re
        
        # Convert to lowercase
        text = text.lower()
        
        # Remove accents
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        
        # Replace spaces and special characters with separator
        text = re.sub(r'[^\w\s-]', '', text)
        text = re.sub(r'[-\s]+', separator, text)
        
        # Remove leading/trailing separators
        text = text.strip(separator)
        
        return text

# Fallback slugify function
def fallback_slugify(text, separator="-"):
    """Simple slugify function"""
    import unicodedata
    import re
    
    # Convert to lowercase
    text = text.lower()
    
    # Remove accents
    text = unicodedata.normalize('NFD', text)
    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
    
    # Replace spaces and special characters with separator
    text = re.sub(r'[^\w\s-]', '', text)
    text = re.sub(r'[-\s]+', separator, text)
    
    # Remove leading/trailing separators
    text = text.strip(separator)
    
    return text

# Ensure slugify is callable with the right signature
def safe_slugify(text, separator="-"):
    """Safe slugify function that works with pymdownx.slugs.slugify"""
    try:
        # Try the correct signature for pymdownx.slugs.slugify
        return slugify(text, max_length=0, word_boundary=False, separator=separator, stopwords=None)
    except TypeError:
        try:
            # Try with just text and separator
            return slugify(text, separator=separator)
        except TypeError:
            try:
                # Try with just text
                return slugify(text)
            except TypeError:
                # Use fallback function
                return fallback_slugify(text, separator)

class AnchorsDoctor:
    def __init__(self, src_dir: str = "docs"):
        self.src_dir = Path(src_dir).resolve()
        self.anchors_found = {}  # page -> set of anchors
        self.broken_links = []   # list of broken links
        self.fixes_applied = []  # list of applied fixes
        self.safe_fixes = []     # list of safe fixes that can be applied
        
    def check_anchors(self, dry_run: bool = False) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —è–∫–æ—Ä–Ω—ã—Ö —Å—Å—ã–ª–æ–∫"""
        print("üîó –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ —è–∫–æ—Ä–Ω—ã—Ö —Å—Å—ã–ª–æ–∫...")
        print(f"  üìÅ –ò—Å—Ö–æ–¥–Ω–∏–∫–∏: {self.src_dir}")
        
        if not self.src_dir.exists():
            print("‚ùå –ü–∞–ø–∫–∞ —Å –∏—Å—Ö–æ–¥–Ω–∏–∫–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return False
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —è–∫–æ—Ä—è –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        self._collect_anchors()
        print(f"  üìã –ù–∞–π–¥–µ–Ω–æ —è–∫–æ—Ä–µ–π: {sum(len(anchors) for anchors in self.anchors_found.values())}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Å—ã–ª–∫–∏
        self._check_links(dry_run)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç—ã
        self._save_reports()
        
        # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
        self._print_report()
        
        return len(self.broken_links) == 0
    
    def _collect_anchors(self):
        """–°–±–æ—Ä —è–∫–æ—Ä–µ–π –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"""
        md_files = list(self.src_dir.rglob('*.md'))
        
        for md_file in md_files:
            try:
                content = md_file.read_text(encoding='utf-8')
                relative_path = str(md_file.relative_to(self.src_dir))
                
                # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ (##, ###, ####, etc.)
                header_pattern = r'^(#{1,6})\s+(.+)$'
                anchors = set()
                
                for line in content.split('\n'):
                    match = re.match(header_pattern, line.strip())
                    if match:
                        level = len(match.group(1))
                        title = match.group(2).strip()
                        
                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º slug –∏—Å–ø–æ–ª—å–∑—É—è pymdownx.slugs.slugify
                        slug = safe_slugify(title, separator="-")
                        anchors.add(slug)
                
                if anchors:
                    self.anchors_found[relative_path] = anchors
                    
            except Exception as e:
                print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {md_file}: {e}")
    
    def _check_links(self, dry_run: bool = False):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Å—ã–ª–æ–∫ –≤ Markdown —Ñ–∞–π–ª–∞—Ö"""
        md_files = list(self.src_dir.rglob('*.md'))
        
        for md_file in md_files:
            try:
                content = md_file.read_text(encoding='utf-8')
                relative_path = str(md_file.relative_to(self.src_dir))
                
                # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–æ–∫ —Å —è–∫–æ—Ä—è–º–∏
                link_patterns = [
                    # [text](#anchor)
                    r'\[([^\]]+)\]\(#([^)]+)\)',
                    # [text](file.md#anchor)
                    r'\[([^\]]+)\]\(([^#]+)#([^)]+)\)',
                    # [text](file.md) - —Å—Å—ã–ª–∫–∏ –±–µ–∑ —è–∫–æ—Ä—è (–ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞)
                    r'\[([^\]]+)\]\(([^#)]+)\)',
                ]
                
                for pattern in link_patterns:
                    for match in re.finditer(pattern, content):
                        if len(match.groups()) == 2:
                            # –°—Å—ã–ª–∫–∞ —Å —è–∫–æ—Ä–µ–º –≤ —Ç–µ–∫—É—â–µ–º —Ñ–∞–π–ª–µ
                            text, anchor = match.groups()
                            self._check_anchor_link(relative_path, relative_path, anchor, match.group(0), dry_run)
                        elif len(match.groups()) == 3:
                            # –°—Å—ã–ª–∫–∞ —Å —è–∫–æ—Ä–µ–º –≤ –¥—Ä—É–≥–æ–º —Ñ–∞–π–ª–µ
                            text, file_path, anchor = match.groups()
                            self._check_anchor_link(relative_path, file_path, anchor, match.group(0), dry_run)
                        else:
                            # –°—Å—ã–ª–∫–∞ –±–µ–∑ —è–∫–æ—Ä—è - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                            text, file_path = match.groups()
                            self._check_file_link(relative_path, file_path, match.group(0), dry_run)
                            
            except Exception as e:
                print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {md_file}: {e}")
    
    def _check_anchor_link(self, source_page: str, target_file: str, anchor: str, full_link: str, dry_run: bool):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Å—ã–ª–∫–∏ —Å —è–∫–æ—Ä–µ–º"""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤–æ–π —Ñ–∞–π–ª
        if target_file == source_page:
            # –°—Å—ã–ª–∫–∞ –Ω–∞ —è–∫–æ—Ä—å –≤ —Ç–µ–∫—É—â–µ–º —Ñ–∞–π–ª–µ
            target_page = source_page
        else:
            # –°—Å—ã–ª–∫–∞ –Ω–∞ —è–∫–æ—Ä—å –≤ –¥—Ä—É–≥–æ–º —Ñ–∞–π–ª–µ
            target_page = self._resolve_file_path(source_page, target_file)
            if not target_page:
                self.broken_links.append({
                    'page': source_page,
                    'original_link': full_link,
                    'target_file': target_file,
                    'broken_anchor': f"#{anchor}",
                    'status': 'Target file not found',
                    'suggestion': ''
                })
                return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —è–∫–æ—Ä—è
        if target_page in self.anchors_found:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —è–∫–æ—Ä—å
            normalized_anchor = safe_slugify(anchor, separator="-")
            
            if normalized_anchor in self.anchors_found[target_page]:
                # –Ø–∫–æ—Ä—å –Ω–∞–π–¥–µ–Ω
                return
            else:
                # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —è–∫–æ—Ä—è
                similar_anchor = self._find_similar_anchor(normalized_anchor, target_page)
                if similar_anchor:
                    # –ù–∞—à–ª–∏ –ø–æ—Ö–æ–∂–∏–π —è–∫–æ—Ä—å - —ç—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                    self.safe_fixes.append({
                        'page': source_page,
                        'original_link': full_link,
                        'target_file': target_file,
                        'broken_anchor': f"#{anchor}",
                        'status': 'Similar anchor found',
                        'suggestion': full_link.replace(f"#{anchor}", f"#{similar_anchor}")
                    })
                    if not dry_run:
                        self._apply_fix(source_page, full_link, full_link.replace(f"#{anchor}", f"#{similar_anchor}"))
                else:
                    # –Ø–∫–æ—Ä—å –Ω–µ –Ω–∞–π–¥–µ–Ω
                    self.broken_links.append({
                        'page': source_page,
                        'original_link': full_link,
                        'target_file': target_file,
                        'broken_anchor': f"#{anchor}",
                        'status': 'Anchor not found',
                        'suggestion': ''
                    })
        else:
            # –¶–µ–ª–µ–≤–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö
            self.broken_links.append({
                'page': source_page,
                'original_link': full_link,
                'target_file': target_file,
                'broken_anchor': f"#{anchor}",
                'status': 'Target file not scanned',
                'suggestion': ''
            })
    
    def _check_file_link(self, source_page: str, target_file: str, full_link: str, dry_run: bool):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª –±–µ–∑ —è–∫–æ—Ä—è"""
        target_page = self._resolve_file_path(source_page, target_file)
        if not target_page:
            self.broken_links.append({
                'page': source_page,
                'original_link': full_link,
                'target_file': target_file,
                'broken_anchor': '',
                'status': 'File not found',
                'suggestion': ''
            })
    
    def _resolve_file_path(self, source_page: str, target_file: str) -> Optional[str]:
        """–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É"""
        # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ docs/
        if target_file in self.anchors_found:
            return target_file
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Å—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        source_path = self.src_dir / source_page
        possible_paths = [
            source_path.parent / target_file,
            source_path.parent / f"{target_file}.md",
            self.src_dir / target_file,
            self.src_dir / f"{target_file}.md",
        ]
        
        for path in possible_paths:
            if path.exists() and path.suffix == '.md':
                relative_path = str(path.relative_to(self.src_dir))
                if relative_path in self.anchors_found:
                    return relative_path
        
        return None
    
    def _find_similar_anchor(self, anchor: str, target_page: str) -> Optional[str]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–µ–≥–æ —è–∫–æ—Ä—è"""
        if target_page not in self.anchors_found:
            return None
        
        available_anchors = self.anchors_found[target_page]
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (—É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤—ã—à–µ)
        if anchor in available_anchors:
            return anchor
        
        # –ü–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é
        for available_anchor in available_anchors:
            if anchor in available_anchor or available_anchor in anchor:
                return available_anchor
        
        # –ü–æ–∏—Å–∫ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
        for available_anchor in available_anchors:
            if self._similarity(anchor, available_anchor) > 0.8:
                return available_anchor
        
        return None
    
    def _similarity(self, a: str, b: str) -> float:
        """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–µ—Ä–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å—Ç—Ä–æ–∫"""
        if not a or not b:
            return 0.0
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Ç—Ä–æ–∫–∏
        a = a.lower().replace('-', '').replace('_', '')
        b = b.lower().replace('-', '').replace('_', '')
        
        if a == b:
            return 1.0
        
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
        if a in b or b in a:
            return 0.9
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–±—â–∏–µ —Å–ª–æ–≤–∞
        a_words = set(a.split())
        b_words = set(b.split())
        if a_words and b_words:
            common_words = len(a_words & b_words)
            total_words = len(a_words | b_words)
            return common_words / total_words
        
        return 0.0
    
    def _apply_fix(self, page: str, original: str, fixed: str):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫ —Ñ–∞–π–ª—É"""
        page_path = self.src_dir / page
        try:
            content = page_path.read_text(encoding='utf-8')
            new_content = content.replace(original, fixed)
            if new_content != content:
                page_path.write_text(new_content, encoding='utf-8')
                self.fixes_applied.append({
                    'page': page,
                    'original': original,
                    'suggestion': fixed,
                    'status': 'Applied'
                })
        except Exception as e:
            print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ {page}: {e}")
    
    def _save_reports(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤ –≤ CSV"""
        build_dir = Path("build")
        build_dir.mkdir(exist_ok=True)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è –æ—Ç—á–µ—Ç–∞
        all_records = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        for fix in self.fixes_applied:
            all_records.append({
                'page': fix['page'],
                'original_link': fix['original'],
                'target_file': '',
                'broken_anchor': '',
                'status': fix['status'],
                'suggestion': fix['suggestion']
            })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        for fix in self.safe_fixes:
            all_records.append({
                'page': fix['page'],
                'original_link': fix['original_link'],
                'target_file': fix['target_file'],
                'broken_anchor': fix['broken_anchor'],
                'status': fix['status'],
                'suggestion': fix['suggestion']
            })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –±–∏—Ç—ã–µ —Å—Å—ã–ª–∫–∏
        for broken in self.broken_links:
            all_records.append({
                'page': broken['page'],
                'original_link': broken['original_link'],
                'target_file': broken['target_file'],
                'broken_anchor': broken['broken_anchor'],
                'status': broken['status'],
                'suggestion': broken['suggestion']
            })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        with open(build_dir / "anchors_report.csv", "w", newline="", encoding="utf-8") as f:
            fieldnames = ['page', 'original_link', 'target_file', 'broken_anchor', 'status', 'suggestion']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for record in all_records:
                writer.writerow(record)
    
    def _print_report(self):
        """–í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞"""
        print("\n" + "="*60)
        print("üìã –û–¢–ß–ï–¢ –û –ü–†–û–í–ï–†–ö–ï –Ø–ö–û–†–ù–´–• –°–°–´–õ–û–ö")
        print("="*60)
        
        if self.fixes_applied:
            print(f"‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(self.fixes_applied)}")
            for fix in self.fixes_applied[:5]:
                print(f"  {fix['page']}: {fix['original']} ‚Üí {fix['suggestion']}")
            if len(self.fixes_applied) > 5:
                print(f"  ... –∏ –µ—â–µ {len(self.fixes_applied) - 5} –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π")
        
        if self.safe_fixes:
            print(f"üîß –ë–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(self.safe_fixes)}")
            for fix in self.safe_fixes[:5]:
                print(f"  {fix['page']}: {fix['original_link']} ‚Üí {fix['suggestion']}")
            if len(self.safe_fixes) > 5:
                print(f"  ... –∏ –µ—â–µ {len(self.safe_fixes) - 5} –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π")
        
        if self.broken_links:
            print(f"‚ùå –ë–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫: {len(self.broken_links)}")
            for broken in self.broken_links[:10]:
                print(f"  {broken['page']}: {broken['original_link']} ({broken['status']})")
            if len(self.broken_links) > 10:
                print(f"  ... –∏ –µ—â–µ {len(self.broken_links) - 10} –±–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫")
        else:
            print("‚úÖ –í—Å–µ —è–∫–æ—Ä–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –≤–∞–ª–∏–¥–Ω—ã")
        
        print(f"\nüìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: build/anchors_report.csv")
        print("="*60)

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='Check and fix anchor links in MkDocs documentation')
    parser.add_argument('--src', default='docs', help='Source directory (default: docs)')
    parser.add_argument('--dry-run', action='store_true', help='Only generate report, do not apply fixes')
    parser.add_argument('--apply', action='store_true', help='Apply safe fixes')
    
    args = parser.parse_args()
    
    if args.apply and args.dry_run:
        print("‚ùå –ù–µ–ª—å–∑—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å --apply –∏ --dry-run –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ")
        sys.exit(1)
    
    if not args.apply and not args.dry_run:
        print("‚ÑπÔ∏è  –†–µ–∂–∏–º –Ω–µ —É–∫–∞–∑–∞–Ω. –ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ --dry-run")
        args.dry_run = True
    
    doctor = AnchorsDoctor(args.src)
    success = doctor.check_anchors(args.dry_run)
    
    if not success:
        print(f"\n‚ùå –ù–∞–π–¥–µ–Ω–æ {len(doctor.broken_links)} –±–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫")
        print("üìä –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ build/anchors_report.csv")
        sys.exit(1)

if __name__ == "__main__":
    main()